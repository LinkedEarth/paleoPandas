{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21fa280",
   "metadata": {},
   "source": [
    "<img src='https://github.com/LinkedEarth/Logos/raw/master/PYLEOCLIM_logo_HORZ-01.png' width=\"800\">\n",
    "\n",
    "# Loading data into a Pyleoclim Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96192e3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Authors\n",
    "Jordan Landers1\n",
    "\n",
    "1 Department of Earth Sciences, University of Southern California\n",
    "\n",
    "Author1 = {\"name\": \"Jordan Landers\", \"affiliation\": \"Department of Earth Sciences, University of Southern\n",
    "California\", \"email\": \"lplander@usc.edu\", \"orcid\": \"0000-0001-9772-7617\"}\n",
    "\n",
    "## Preamble\n",
    "Contrary to common beliefs, Pyleoclim is not specific to the LiPD file ecosystem.  The object at the heart of the package is the\n",
    "[`Series` object](https://pyleoclim-util.readthedocs.io/en/master/core/ui.html#series-pyleoclim-series), which describes the fundamentals of a time series. To create a\n",
    "Pyleoclim `Series`, we first need to load the data set, and then specify values for its various properties:\n",
    "\n",
    "* `time`: Time values for the time series\n",
    "* `value`: Paleo values for the time series\n",
    "* `time_name` (optional): Name of the time vector, (e.g., 'Time', 'Age'). This is used to label the x-axis on plots\n",
    "* `time_unit` (optional): The units of the time axis (e.g., 'years')\n",
    "* `value_name` (optional): The name of the paleo variable (e.g., 'Temperature')\n",
    "* `value_unit` (optional): The units of the paleo variable (e.g., 'deg C')\n",
    "* `label` (optional): Name of the time series (e.g., 'Nino 3.4')\n",
    "* `clean_ts` (optional): If True (default), remove NaNs and set an increasing time axis.\n",
    "\n",
    "Data may be stored in different file types, which can be ingested in different ways.  \n",
    "\n",
    "### Goals:\n",
    "* Create Pyleoclim Series objects from datasets stored as CSV, NetCDF, LiPD, and NOAA txt files.\n",
    "\n",
    "**Reading Time:** 5 minutes\n",
    "\n",
    "### Keywords\n",
    "\n",
    "CSV; NetCDF; LiPD, Series; EnsembleSeries\n",
    "\n",
    "### Pre-requisites\n",
    "\n",
    "None. This tutorial assumes basic knowledge of Python. If you are not familiar with this coding language, check out this tutorial: http://linked.earth/ec_workshops_py/.\n",
    "\n",
    "### Relevant Packages\n",
    "\n",
    "Pandas; Xarray\n",
    "\n",
    "## Data Description\n",
    "\n",
    "* McCabe-Glynn, S., Johnson, K., Strong, C. et al. Variable\n",
    "North Pacific influence on drought in southwestern North America since AD 854. Nature Geosci 6, 617–621 (2013).\n",
    "[doi:10.1038/ngeo1862](https://doi.org/10.1038/ngeo1862)\n",
    "\n",
    "* Euro2k database: PAGES2k Consortium., Emile-Geay, J., McKay, N. et al. A global multiproxy database for temperature\n",
    " reconstructions of the Common Era. Sci Data 4, 170088 (2017). [doi:10.1038/sdata.2017.88](https://doi.org/10.1038/sdata.2017.88)\n",
    "\n",
    "* Lisiecki, L. E., and Raymo, M. E. (2005), A Pliocene-Pleistocene stack of 57 globally distributed benthic\n",
    "δ18O records, Paleoceanography, 20, PA1003, [doi:10.1029/2004PA001071](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2004PA001071)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a106e375",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Demonstration\n",
    "First we import our favorite package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5288b8e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pyleoclim as pyleo\n",
    "pyleo.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231c6bf4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### LiPD\n",
    "Linked Paleo Data format ([LiPD](http://www.clim-past-discuss.net/11/4309/2015/cpd-11-4309-2015-discussion.html)) files contain time series information in addition to supporting metadata (e.g., root metadata, location).\n",
    "Pyleoclim leverages this additional information using LiPD-specific functionality discussed in greater depth in [this\n",
    " tutorial]().\n",
    "\n",
    "Data stored in the `.lpd` format can be loaded directly into Pyleoclim as a\n",
    "[Lipd object](https://pyleoclim-util.readthedocs.io/en/master/core/api.html?highlight=lipd#pyleoclim.core.lipd.Lipd).\n",
    "If the data_path points to one LiPD file, `pyleo.Lipd` will load the specific record, while if data_path points to a\n",
    "folder of lipd files, `pyleo.Lipd` will load the full set of records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92646f7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Loading a single LiPD file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e97571",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '../data/Crystal.McCabe-Glynn.2013.lpd'\n",
    "d = pyleo.Lipd(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98678cb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As a check to make sure the LiPD file corresponds to the expected record, we can quickly generate a map that\n",
    "indicates the location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e91438",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d.mapAllArchive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733bcc4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Loading multiple LiPD files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d19f3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '../data/Euro2k/'\n",
    "d_multiple = pyleo.Lipd(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03fc4ac",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d_multiple.mapAllArchive(lgd_kwargs={'bbox_to_anchor': (1, 1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026295f4-8bd7-4d64-b638-36d3a7ead575",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### NetCDF\n",
    "In order to load data from a NetCDF file, we will use [Xarray](https://docs.xarray.dev/en/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db100137-3312-4c41-825c-082959bf13f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d568b7c3-7a49-457d-87d6-6408aedb28e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/p2k_ngeo19_recons.nc'\n",
    "p2k_nc = xr.open_dataset(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c56dc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The coordinates of this data set are `year` and `ens`, and the temperature anamoly is contained in the variable\n",
    "`LMRv2.1`. Below we extract the timeseries for the ensemble runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1825fd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "variable_name = 'LMRv2.1'\n",
    "ens_runs = p2k_nc.groupby('ens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25edceda",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To create the `pyleo.Series`, we pass the time coordinate of the dataset, `p2k_nc.year`, as `time`, and one of the ensemble runs as `value`. It is optional to specify `time_name` and `time_unit`, and\n",
    "`value_name` and `value_unit`, but doing so ensures that plot axes are properly labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afd2921-48d6-452c-8a57-3e5694a62e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_run1 = ens_runs[1].data_vars[variable_name]\n",
    "p2k_ps = pyleo.Series(time=p2k_nc.year, value=ens_run1,\n",
    "                      time_name='Time', time_unit='year', label = 'LMRv2.1 member #1',\n",
    "                      value_name='GMST', value_unit='$^{\\circ}$C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ca671-1d78-4f83-ba24-e06d3aadaea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = p2k_ps.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e902cd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "However, given this is an ensemble, capturing this data in a `pyleo.EnsembleSeries` will open up opportunities for\n",
    "specific analysis and visualization. In the cell below, we generate a list of `pyleo.Series` (one for each trace) for\n",
    "the full set of ensemble runs in much the same way as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51401888",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ts_list = []\n",
    "\n",
    "for im in range(len(p2k_nc.ens)):\n",
    "    ens_run = ens_runs[im+1].data_vars[variable_name]\n",
    "    ts_list.append(pyleo.Series(time=p2k_nc.year, value=ens_run,\n",
    "                      time_name='Time', time_unit='year',\n",
    "                      value_name='GMST', value_unit='$^{\\circ}$C'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829eec82",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then we simply pass `ts_list` to `pyleo.EnsembleSeries`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc12842c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ts_ens = pyleo.EnsembleSeries(ts_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6886ab5c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For more detail on visualizing `pyleo.EnsembleSeries`, check out the tutorial on [Basic operations with\n",
    "MultipleSeries and EnsembleSeries](), but we can use `plot_traces()` to quickly check to make sure the data seems\n",
    "properly organized (by default, `plot_traces()` plots 10 randomly selected traces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f3a12",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = ts_ens.plot_traces()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f113ad2-aac8-42b1-82c5-6944c1906f06",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### CSV\n",
    "CSV files have a table structure, so we will use [Pandas](https://pandas.pydata.org) and the read the data into a pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5adbe9a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6cfa84",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LR04 = pd.read_csv('../data/LR04.csv', header=4)\n",
    "LR04.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8579d6f4-bbe9-4b56-884f-26048f4259c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR04.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50356a18",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To create a `pyleo.Series`, we pass the `Time (ka)` column as `time` and the `Benthic d18O (per mil)` column as `value`. Note the extra space at the end of that column name! We have to work with what the interwebs give us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f2cd1e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LR04_ps = pyleo.Series(time=LR04['Time (ka)'], value=LR04['Benthic d18O (per mil)  '],\n",
    "                      time_name='Time', time_unit='ka',\n",
    "                      value_name='$\\delta^{18}$O', value_unit=u'‰')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d19538b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = LR04_ps.plot()\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6fe58e-1837-454b-ac37-897a6e8784e9",
   "metadata": {},
   "source": [
    "### NOAA txt files\n",
    "\n",
    "As you may now, the World Data Service for paleoclimatology, operated by NCEI/NOAA of the US Department of Commerce, hosts thousands of data files in various formats. A common one is a [templated text file](https://www.ncei.noaa.gov/pub/data/paleo/templates/noaa-wds-paleo-template-instructions.txt), containing rich data and metadata. LinkedEarth will soon develop ways to ingest such files directly into LiPD. In the meantime, one can treat the file as a raw text file, ignoring the header and loading the data directly into a [Pandas](https://pandas.pydata.org) `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a295b-34d4-4d74-9c5d-54716f5ef4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'ftp://ftp.ncdc.noaa.gov/pub/data/paleo/icecore/antarctica/antarctica2015co2composite.txt'\n",
    "co2df = pd.read_csv(path, skiprows=137, sep='\\t')\n",
    "co2df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e221bc1d-46e2-4be1-8a82-5132865bd648",
   "metadata": {},
   "source": [
    "Notice how `pandas` retrieved the data over the network, without needing to download a local copy of the file. However, it would work just as well if you did have such a copy on your hardrive, and you would simply replace `path` with the local file path  (everything else would stay the same). We did cheat a bit, however: we had to peak at the file to know how many header lines to skip (137). The separator (`sep`) argument is set to `'\\t'`, which means \"tab\". It works well in this case, but we cannot guarantee that it will work on all NOAA text files.\n",
    "\n",
    "Finally, we pull the relevant columns of this datframe into a Series object, convert the years to kyr for ease of use, and put in the relevant metadata so that we can get a well-labeled, publication-quality plot right off the bat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6637c8-270a-4ad8-aa41-ad88c8a57608",
   "metadata": {},
   "outputs": [],
   "source": [
    "co2ts = pyleo.Series(time=co2df['age_gas_calBP']/1000,value= co2df['co2_ppm'],time_name='Age',time_unit='kyr BP',value_name = r'$CO_2$',value_unit='ppm',label='EPICA Dome C CO2')\n",
    "co2ts.plot(color='C1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f9ae9-772e-4c3f-a129-fdf2effce24b",
   "metadata": {},
   "source": [
    "## Loading from PANGAEA\n",
    "\n",
    "Another major repository for paleoclimate data is [PANGAEA](https://www.pangaea.de). Here we load the dataset of [Skinner et al. (2007)](https://doi.pangaea.de/10.1594/PANGAEA.619066), using their very helpful [pangaeapy](https://github.com/pangaea-data-publisher/pangaeapy) package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d3c301-687e-4774-bee3-9ef9b47eac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangaeapy.pandataset import PanDataSet\n",
    "\n",
    "ds = PanDataSet('10.1594/PANGAEA.619066')\n",
    "print(ds.title)\n",
    "print(ds.data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be940d04-cdfe-4923-b5b6-9b420a1f863c",
   "metadata": {},
   "source": [
    "Once again, this method eschewed a download, retrieving the data directly from PANGAEA's web server. Notice that all you needed was the dataset DOI, easily gleaned from the page's URL or from the contents themselves.  The `PanDataSet` is a custom data structure built on `pandas`, much in the way Pyleoclim `Series` will be in a few releases. \n",
    "\n",
    "One can extract the dataset column names via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38233b5-f248-4fa7-abef-5197177bd64b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46167ca7-ae65-474a-85ce-e5536b3afa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ds.data['Temp']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f0042-07b9-4174-b087-4635bc7161c3",
   "metadata": {},
   "source": [
    "As a pandas Series object, this variable has an associated plot method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21635d7-e49f-483b-8860-ab5ce19ff199",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.data['Temp'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c912674-b8e5-434b-8062-53e38f21d8c0",
   "metadata": {},
   "source": [
    "However, we see that the x-axis knows nothing about time; indeed, PANGAEA services a dizzying array of dataset types, and their API has to be very general. This is one reason to have a Pyleoclim Series class that knows explicitly about time. Let us create an instance here, with proper metadata that are not available in the original, barebones PANGAEA format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86bebe8-a447-4243-a1a6-cfedd23fc1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "S07_temp = pyleo.Series(time=ds.data['Age'], value=ds.data['Temp'],\n",
    "                      time_name='Age', time_unit='ka BP',\n",
    "                      value_name='Temperature', value_unit=r'$^{\\circ}$ C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c0615-332d-459b-9420-7fd588b44452",
   "metadata": {},
   "outputs": [],
   "source": [
    "S07_temp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22837d7b-95aa-4ead-84b6-5909dda16644",
   "metadata": {},
   "source": [
    "As of now, you can create this object manually, but we will soon automate this process to a large extent. Let us also load their reconstruction of seawater $\\delta^{18}$O:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a3e8e-6bfa-4584-b15a-87f45e6d9058",
   "metadata": {},
   "outputs": [],
   "source": [
    "S07_d18Osw = pyleo.Series(time=ds.data['Age'], value=ds.data['δ18O H2O'],\n",
    "                      time_name='Age', time_unit='ka BP',\n",
    "                      value_name='seawater $\\delta^{18}$O', value_unit='$\\perthousand$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e3c70d-cfd8-45f2-9df4-801d62d581c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "S07_d18Osw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032bba6-fe4f-4bdb-a714-f705488feb19",
   "metadata": {},
   "source": [
    "We can put both series into a [MultipleSeries](https://pyleoclim-util.readthedocs.io/en/master/core/api.html#multipleseries-pyleoclim-multipleseries) object, which unlocks fun features, like `stackplot()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e8f8d-55b0-49e6-9f8f-0b9e71e13f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = pyleo.MultipleSeries([S07_temp,S07_d18Osw])\n",
    "ms.stackplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9638384e-788e-4eb8-a51b-eb707b040188",
   "metadata": {},
   "source": [
    "For more information on `MultipleSeries`, read the [documentation](https://pyleoclim-util.readthedocs.io/en/master/core/api.html#multipleseries-pyleoclim-multipleseries) and/or follow the tutorial `basic_MSES_manipulation.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1592f7-6177-41ec-a52b-dbfcf5d5aa7c",
   "metadata": {},
   "source": [
    "## Takeway\n",
    "\n",
    "There are multiple paths into Series, unlocking the full power of `Pyleoclim` to work with data originally stored in all manner of formats. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
